{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Whale Intelligence - Erklaert\n",
    "\n",
    "Dieses Notebook erklaert Schritt fuer Schritt, wie wir Bitcoin-\"Wale\" (grosse Besitzer) identifizieren.\n",
    "\n",
    "**Das Problem:** Auf der Blockchain sehen wir nur Adressen, nicht Personen. Ein Besitzer kann hunderte Adressen haben.\n",
    "\n",
    "**Die Loesung:** Wir gruppieren Adressen, die wahrscheinlich derselben Person gehoeren.\n",
    "\n",
    "---\n",
    "\n",
    "| Abschnitt | Beschreibung |\n",
    "|-----------|--------------|\n",
    "| 1. Das Problem | Warum Whale-Analyse? |\n",
    "| 2. UTXO-Modell | Bitcoin hat keine Konten |\n",
    "| 3. Daten laden | JSON zu Spark DataFrames |\n",
    "| 4. Outputs extrahieren | Nested zu Flach |\n",
    "| 5. Inputs extrahieren | Nested zu Flach |\n",
    "| 6. UTXO berechnen | Unspent Outputs finden |\n",
    "| 7. Common Input Heuristic | Adressen gruppieren |\n",
    "| 8. Graph bauen | Adressen als Netzwerk |\n",
    "| 9. Connected Components | Entities finden |\n",
    "| 10. Whale Detection | Grosse Besitzer finden |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Das Problem: Adressen sind nicht Personen\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    WAS WIR AUF DER BLOCKCHAIN SEHEN                 │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   ┌───────────────┐   ┌───────────────┐   ┌───────────────┐        │\n",
    "│   │  Adresse A    │   │  Adresse B    │   │  Adresse C    │        │\n",
    "│   │   500 BTC     │   │   300 BTC     │   │   200 BTC     │        │\n",
    "│   └───────────────┘   └───────────────┘   └───────────────┘        │\n",
    "│                                                                     │\n",
    "│   Sieht aus wie 3 verschiedene Besitzer mit je 200-500 BTC         │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ Analyse\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    DIE REALITAET (versteckt)                        │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│           ┌───────────────────────────────────────┐                 │\n",
    "│           │         EINE PERSON / ENTITY          │                 │\n",
    "│           │              1.000 BTC                │                 │\n",
    "│           │   (kontrolliert A, B und C)           │                 │\n",
    "│           └───────────────────────────────────────┘                 │\n",
    "│                                                                     │\n",
    "│   Das ist ein WAL! Aber ohne Analyse wuerden wir es nicht sehen.   │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Boersen haben tausende Adressen\n",
    "- Privacy-bewusste Nutzer verwenden neue Adressen pro Transaktion\n",
    "- Echte Vermoegensverteilung ist ohne Clustering unsichtbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Das UTXO-Modell: Bitcoin hat keine \"Konten\"\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                      BANK-MODELL (Nicht Bitcoin!)                   │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   Konto 123:  Kontostand = 1.000 EUR                               │\n",
    "│               ─────────────────────                                 │\n",
    "│               Eine Zahl, die aktualisiert wird                      │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                      BITCOIN: UTXO-MODELL                           │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   Adresse A besitzt diese \"Muenzen\" (UTXOs):                       │\n",
    "│                                                                     │\n",
    "│   ┌─────────┐  ┌─────────┐  ┌─────────┐                            │\n",
    "│   │ 0.5 BTC │  │ 0.3 BTC │  │ 0.2 BTC │  = 1.0 BTC Guthaben        │\n",
    "│   └─────────┘  └─────────┘  └─────────┘                            │\n",
    "│                                                                     │\n",
    "│   Wie Bargeld-Scheine: Jeder UTXO ist eine separate \"Muenze\"       │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Eine Bitcoin-Transaktion funktioniert so:**\n",
    "\n",
    "```\n",
    "┌─────────────────┐                         ┌─────────────────┐\n",
    "│    INPUTS       │                         │    OUTPUTS      │\n",
    "│  (ausgeben)     │                         │  (neue UTXOs)   │\n",
    "├─────────────────┤     ┌───────────┐       ├─────────────────┤\n",
    "│  ┌───────────┐  │     │           │       │  ┌───────────┐  │\n",
    "│  │  0.5 BTC  │──┼────▶│           │──────▶│  │  0.7 BTC  │  │  Empfaenger\n",
    "│  └───────────┘  │     │    TX     │       │  └───────────┘  │\n",
    "│  ┌───────────┐  │     │           │       │  ┌───────────┐  │\n",
    "│  │  0.3 BTC  │──┼────▶│           │──────▶│  │ 0.09 BTC  │  │  Wechselgeld\n",
    "│  └───────────┘  │     └───────────┘       │  └───────────┘  │\n",
    "└─────────────────┘      Gebuehr: 0.01      └─────────────────┘\n",
    "    0.8 BTC rein             BTC               0.79 BTC raus\n",
    "```\n",
    "\n",
    "**Wichtig:** Um einen UTXO auszugeben, braucht man den Private Key der Adresse!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Setup und Konfiguration\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                        DATENQUELLE                                  │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  ┌──────────────┐      ┌──────────────┐      ┌──────────────┐      │\n",
    "│  │   Bitcoin    │      │  bitcoin-etl │      │    JSON      │      │\n",
    "│  │  Full Node   │─────▶│   (Export)   │─────▶│   Dateien    │      │\n",
    "│  └──────────────┘      └──────────────┘      └──────────────┘      │\n",
    "│                                                                     │\n",
    "│  Die Blockchain        Konvertiert zu        Unser Input           │\n",
    "│  (900+ GB)             lesbarem Format       (Blocks + TXs)        │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Warum Spark?** Die Blockchain ist riesig. Spark verteilt die Arbeit auf alle CPU-Kerne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# IMPORTS\n",
    "# ==============================================================================\n",
    "import os\n",
    "import platform\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import (\n",
    "    col, count, sum as spark_sum, avg, desc, when, round as spark_round,\n",
    "    explode, explode_outer, collect_set, size as spark_size,\n",
    "    from_unixtime, to_timestamp, element_at\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, LongType, IntegerType,\n",
    "    BooleanType, ArrayType\n",
    ")\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# Visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (12, 6),\n",
    "    'figure.dpi': 100,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.labelsize': 11,\n",
    "    'font.size': 10\n",
    "})\n",
    "COLORS = {'primary': '#2E86AB', 'secondary': '#A23B72', 'accent': '#F18F01', 'dark': '#1B1B1E'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# KONFIGURATION - PASSE DIE PFADE AN DEIN SYSTEM AN\n",
    "# ==============================================================================\n",
    "\n",
    "SYSTEM = platform.system()\n",
    "\n",
    "# Pfad zu bitcoin-etl exportierten Daten\n",
    "# Beispiele:\n",
    "#   Windows: r\"C:\\Users\\DeinName\\blockchain_exports\"\n",
    "#   macOS:   \"/Users/DeinName/blockchain_exports\"\n",
    "#   Linux:   \"/home/DeinName/blockchain_exports\"\n",
    "\n",
    "if SYSTEM == \"Windows\":\n",
    "    BLOCKCHAIN_DATA_PATH = r\"C:\\Users\\YourName\\blockchain_exports\"  # <-- AENDERN\n",
    "    OUTPUT_PATH = r\"C:\\Users\\YourName\\bitcoin_analysis_output\"       # <-- AENDERN\n",
    "elif SYSTEM == \"Darwin\":  # macOS\n",
    "    BLOCKCHAIN_DATA_PATH = \"/Users/roman/spark_project/blockchain_exports\"  # <-- AENDERN\n",
    "    OUTPUT_PATH = \"/Users/roman/spark_project/bitcoin-whale-intelligence/data\"\n",
    "else:  # Linux\n",
    "    BLOCKCHAIN_DATA_PATH = \"/home/YourName/blockchain_exports\"  # <-- AENDERN\n",
    "    OUTPUT_PATH = \"/home/YourName/bitcoin_analysis_output\"\n",
    "\n",
    "DRIVER_MEMORY = \"16g\"\n",
    "\n",
    "# Output-Verzeichnis erstellen\n",
    "Path(OUTPUT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"System: {SYSTEM}\")\n",
    "print(f\"Datenquelle: {BLOCKCHAIN_DATA_PATH}\")\n",
    "print(f\"Output-Pfad: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Schemas und Helper-Funktionen\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    JSON STRUKTUR (bitcoin-etl)                      │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  Transaction JSON:                                                  │\n",
    "│  {                                                                  │\n",
    "│    \"hash\": \"abc123...\",                                            │\n",
    "│    \"block_number\": 100000,                                         │\n",
    "│    \"inputs\": [                      <-- Array von Inputs           │\n",
    "│      { \"spent_transaction_hash\": \"xyz\", \"value\": 50000000 }       │\n",
    "│    ],                                                               │\n",
    "│    \"outputs\": [                     <-- Array von Outputs          │\n",
    "│      { \"index\": 0, \"value\": 40000000, \"addresses\": [\"1A...\"] }    │\n",
    "│    ]                                                                │\n",
    "│  }                                                                  │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Warum Schemas?** Spark kann die Daten schneller laden, wenn es die Struktur vorher kennt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SCHEMAS FUER BITCOIN-ETL JSON DATEN\n",
    "# ==============================================================================\n",
    "\n",
    "INPUT_SCHEMA = StructType([\n",
    "    StructField(\"index\", IntegerType(), True),\n",
    "    StructField(\"spent_transaction_hash\", StringType(), True),\n",
    "    StructField(\"spent_output_index\", IntegerType(), True),\n",
    "    StructField(\"script_asm\", StringType(), True),\n",
    "    StructField(\"script_hex\", StringType(), True),\n",
    "    StructField(\"sequence\", LongType(), True),\n",
    "    StructField(\"required_signatures\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"addresses\", ArrayType(StringType()), True),\n",
    "    StructField(\"value\", LongType(), True),\n",
    "])\n",
    "\n",
    "OUTPUT_SCHEMA = StructType([\n",
    "    StructField(\"index\", IntegerType(), True),\n",
    "    StructField(\"script_asm\", StringType(), True),\n",
    "    StructField(\"script_hex\", StringType(), True),\n",
    "    StructField(\"required_signatures\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"addresses\", ArrayType(StringType()), True),\n",
    "    StructField(\"value\", LongType(), True),\n",
    "])\n",
    "\n",
    "TRANSACTION_SCHEMA = StructType([\n",
    "    StructField(\"hash\", StringType(), False),\n",
    "    StructField(\"size\", IntegerType(), True),\n",
    "    StructField(\"virtual_size\", IntegerType(), True),\n",
    "    StructField(\"version\", IntegerType(), True),\n",
    "    StructField(\"lock_time\", LongType(), True),\n",
    "    StructField(\"block_number\", LongType(), True),\n",
    "    StructField(\"block_hash\", StringType(), True),\n",
    "    StructField(\"block_timestamp\", LongType(), True),\n",
    "    StructField(\"is_coinbase\", BooleanType(), True),\n",
    "    StructField(\"index\", IntegerType(), True),\n",
    "    StructField(\"inputs\", ArrayType(INPUT_SCHEMA), True),\n",
    "    StructField(\"outputs\", ArrayType(OUTPUT_SCHEMA), True),\n",
    "    StructField(\"input_count\", IntegerType(), True),\n",
    "    StructField(\"output_count\", IntegerType(), True),\n",
    "    StructField(\"input_value\", LongType(), True),\n",
    "    StructField(\"output_value\", LongType(), True),\n",
    "    StructField(\"fee\", LongType(), True),\n",
    "])\n",
    "\n",
    "BLOCK_SCHEMA = StructType([\n",
    "    StructField(\"hash\", StringType(), False),\n",
    "    StructField(\"size\", IntegerType(), True),\n",
    "    StructField(\"stripped_size\", IntegerType(), True),\n",
    "    StructField(\"weight\", IntegerType(), True),\n",
    "    StructField(\"number\", LongType(), True),\n",
    "    StructField(\"version\", IntegerType(), True),\n",
    "    StructField(\"merkle_root\", StringType(), True),\n",
    "    StructField(\"timestamp\", LongType(), True),\n",
    "    StructField(\"nonce\", StringType(), True),\n",
    "    StructField(\"bits\", StringType(), True),\n",
    "    StructField(\"coinbase_param\", StringType(), True),\n",
    "    StructField(\"transaction_count\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "print(\"Schemas definiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# HELPER FUNKTIONEN\n",
    "# ==============================================================================\n",
    "\n",
    "def create_spark_session(app_name=\"Bitcoin Whale Intelligence\", driver_memory=\"8g\",\n",
    "                         enable_graphframes=True, suppress_logs=True):\n",
    "    \"\"\"\n",
    "    Erstellt eine optimierte Spark Session fuer Bitcoin-Datenverarbeitung.\n",
    "    \"\"\"\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(app_name) \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", driver_memory) \\\n",
    "        .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "        .config(\"spark.sql.adaptive.skewJoin.enabled\", \"true\") \\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "        .config(\"spark.sql.debug.maxToStringFields\", \"100\") \\\n",
    "        .config(\"spark.ui.showConsoleProgress\", \"false\") \\\n",
    "        .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "        .config(\"spark.memory.storageFraction\", \"0.3\")\n",
    "\n",
    "    if enable_graphframes:\n",
    "        builder = builder.config(\n",
    "            \"spark.jars.packages\",\n",
    "            \"graphframes:graphframes:0.8.3-spark3.5-s_2.12\"\n",
    "        )\n",
    "\n",
    "    if suppress_logs:\n",
    "        devnull = os.open(os.devnull, os.O_WRONLY)\n",
    "        old_stdout_fd = os.dup(1)\n",
    "        old_stderr_fd = os.dup(2)\n",
    "        os.dup2(devnull, 1)\n",
    "        os.dup2(devnull, 2)\n",
    "        try:\n",
    "            spark = builder.getOrCreate()\n",
    "            spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "        finally:\n",
    "            os.dup2(old_stdout_fd, 1)\n",
    "            os.dup2(old_stderr_fd, 2)\n",
    "            os.close(devnull)\n",
    "            os.close(old_stdout_fd)\n",
    "            os.close(old_stderr_fd)\n",
    "    else:\n",
    "        spark = builder.getOrCreate()\n",
    "        spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "    return spark\n",
    "\n",
    "\n",
    "def load_transactions(spark, base_path, use_schema=True):\n",
    "    \"\"\"\n",
    "    Laedt bitcoin-etl Transaktionsdaten aus Hive-partitionierten JSON-Dateien.\n",
    "    \"\"\"\n",
    "    base = Path(base_path)\n",
    "    batch_folders = [d for d in base.iterdir() if d.is_dir() and not d.name.startswith('.')]\n",
    "\n",
    "    if not batch_folders:\n",
    "        raise ValueError(f\"Keine Batch-Ordner gefunden in {base_path}\")\n",
    "\n",
    "    tx_paths = []\n",
    "    for batch in batch_folders:\n",
    "        tx_path = batch / \"transactions\"\n",
    "        if tx_path.exists():\n",
    "            tx_paths.append(str(tx_path))\n",
    "\n",
    "    if not tx_paths:\n",
    "        raise ValueError(\"Keine transactions/ Ordner gefunden\")\n",
    "\n",
    "    if use_schema:\n",
    "        df = spark.read.schema(TRANSACTION_SCHEMA).json(tx_paths)\n",
    "    else:\n",
    "        df = spark.read.json(tx_paths)\n",
    "\n",
    "    df = df.withColumn(\"block_datetime\", to_timestamp(from_unixtime(col(\"block_timestamp\"))))\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_blocks(spark, base_path, use_schema=True):\n",
    "    \"\"\"\n",
    "    Laedt bitcoin-etl Block-Daten aus Hive-partitionierten JSON-Dateien.\n",
    "    \"\"\"\n",
    "    base = Path(base_path)\n",
    "    batch_folders = [d for d in base.iterdir() if d.is_dir() and not d.name.startswith('.')]\n",
    "\n",
    "    block_paths = []\n",
    "    for batch in batch_folders:\n",
    "        block_path = batch / \"blocks\"\n",
    "        if block_path.exists():\n",
    "            block_paths.append(str(block_path))\n",
    "\n",
    "    if not block_paths:\n",
    "        raise ValueError(\"Keine blocks/ Ordner gefunden\")\n",
    "\n",
    "    if use_schema:\n",
    "        df = spark.read.schema(BLOCK_SCHEMA).json(block_paths)\n",
    "    else:\n",
    "        df = spark.read.json(block_paths)\n",
    "\n",
    "    df = df.withColumn(\"timestamp_dt\", to_timestamp(from_unixtime(col(\"timestamp\"))))\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Helper-Funktionen definiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Spark initialisieren\n",
    "spark = create_spark_session(app_name=\"Bitcoin Whale Analysis\", driver_memory=DRIVER_MEMORY, enable_graphframes=True)\n",
    "spark.sparkContext.setCheckpointDir(str(Path(OUTPUT_PATH) / \"checkpoints\"))\n",
    "print(f\"Spark {spark.version} initialisiert | UI: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Daten laden: JSON zu Spark DataFrames\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                         DATEN LADEN                                 │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  blockchain_exports/                                                │\n",
    "│  ├── batch_0/                                                       │\n",
    "│  │   ├── blocks/                                                    │\n",
    "│  │   │   └── *.json         ──┐                                    │\n",
    "│  │   └── transactions/         │                                    │\n",
    "│  │       └── *.json         ───┼──▶  Spark DataFrame               │\n",
    "│  ├── batch_1/                  │     (verteilt auf alle Kerne)     │\n",
    "│  │   └── ...                ───┘                                    │\n",
    "│  └── ...                                                            │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                                 │\n",
    "                                 ▼\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│  tx_df:                                                             │\n",
    "│  ┌────────────┬─────────────┬────────────┬────────────┐            │\n",
    "│  │    hash    │ block_num   │  inputs[]  │ outputs[]  │            │\n",
    "│  ├────────────┼─────────────┼────────────┼────────────┤            │\n",
    "│  │  abc123... │   100000    │   [...]    │   [...]    │            │\n",
    "│  │  def456... │   100000    │   [...]    │   [...]    │            │\n",
    "│  │    ...     │    ...      │    ...     │    ...     │            │\n",
    "│  └────────────┴─────────────┴────────────┴────────────┘            │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Warum .cache()?** Die Daten werden im RAM gehalten, damit nachfolgende Operationen schneller sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Transaktionen und Bloecke laden\n",
    "tx_df = load_transactions(spark, BLOCKCHAIN_DATA_PATH).cache()\n",
    "blocks_df = load_blocks(spark, BLOCKCHAIN_DATA_PATH).cache()\n",
    "\n",
    "TX_COUNT = tx_df.count()\n",
    "BLOCK_COUNT = blocks_df.count()\n",
    "\n",
    "print(f\"Geladen: {TX_COUNT:,} Transaktionen aus {BLOCK_COUNT:,} Bloecken\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Outputs extrahieren: Verschachtelt zu Flach\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    VORHER: VERSCHACHTELT (Nested)                   │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  Transaction: \"abc123\"                                              │\n",
    "│  outputs: [                                                         │\n",
    "│    { index: 0, value: 5000000000, addresses: [\"1A...\"] },          │\n",
    "│    { index: 1, value: 2000000000, addresses: [\"1B...\"] }           │\n",
    "│  ]                                                                  │\n",
    "│                                                                     │\n",
    "│  --> 1 Zeile mit Array                                              │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                                 │\n",
    "                                 │ explode()\n",
    "                                 ▼\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    NACHHER: FLACH (Flat)                            │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  ┌──────────┬─────────────┬──────────────┬────────────┐            │\n",
    "│  │  tx_hash │ output_idx  │    value     │  addresses │            │\n",
    "│  ├──────────┼─────────────┼──────────────┼────────────┤            │\n",
    "│  │ abc123   │      0      │  5000000000  │  [\"1A...\"] │            │\n",
    "│  │ abc123   │      1      │  2000000000  │  [\"1B...\"] │            │\n",
    "│  └──────────┴─────────────┴──────────────┴────────────┘            │\n",
    "│                                                                     │\n",
    "│  --> 2 Zeilen, jede fuer einen Output                               │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Warum flach?** So koennen wir jeden Output einzeln analysieren, joinen und aggregieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_outputs(tx_df):\n",
    "    \"\"\"\n",
    "    Transformiert verschachtelte Outputs zu einer flachen Tabelle.\n",
    "    Jede Zeile = 1 Output.\n",
    "    \"\"\"\n",
    "    return tx_df \\\n",
    "        .select(\n",
    "            col(\"hash\").alias(\"tx_hash\"),\n",
    "            col(\"block_number\"),\n",
    "            col(\"block_timestamp\"),\n",
    "            explode_outer(\"outputs\").alias(\"output\")\n",
    "        ) \\\n",
    "        .select(\n",
    "            \"tx_hash\",\n",
    "            \"block_number\",\n",
    "            \"block_timestamp\",\n",
    "            col(\"output.index\").alias(\"output_index\"),\n",
    "            col(\"output.value\").alias(\"value\"),\n",
    "            col(\"output.addresses\").alias(\"addresses\"),\n",
    "            col(\"output.type\").alias(\"output_type\"),\n",
    "        )\n",
    "\n",
    "# Outputs extrahieren\n",
    "outputs_df = explode_outputs(tx_df).cache()\n",
    "OUTPUT_COUNT = outputs_df.count()\n",
    "print(f\"Outputs extrahiert: {OUTPUT_COUNT:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Inputs extrahieren: Welche Outputs wurden ausgegeben?\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    VORHER: VERSCHACHTELT (Nested)                   │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  Transaction: \"def456\"                                              │\n",
    "│  inputs: [                                                          │\n",
    "│    { spent_transaction_hash: \"abc123\", spent_output_index: 0 },    │\n",
    "│    { spent_transaction_hash: \"xyz789\", spent_output_index: 1 }     │\n",
    "│  ]                                                                  │\n",
    "│                                                                     │\n",
    "│  --> Diese TX gibt 2 vorherige Outputs aus                          │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                                 │\n",
    "                                 │ explode()\n",
    "                                 ▼\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    NACHHER: FLACH (Flat)                            │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  ┌──────────┬────────────────┬───────────────────┐                 │\n",
    "│  │  tx_hash │  spent_tx_hash │ spent_output_idx  │                 │\n",
    "│  ├──────────┼────────────────┼───────────────────┤                 │\n",
    "│  │ def456   │     abc123     │         0         │  <-- Referenz   │\n",
    "│  │ def456   │     xyz789     │         1         │      auf alte   │\n",
    "│  └──────────┴────────────────┴───────────────────┘      Outputs    │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Wichtig:** Ein Input ist eine REFERENZ auf einen alten Output. Der Input \"verbraucht\" diesen Output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_inputs(tx_df):\n",
    "    \"\"\"\n",
    "    Transformiert verschachtelte Inputs zu einer flachen Tabelle.\n",
    "    Jede Zeile = 1 Input (= 1 ausgegebener Output).\n",
    "    \"\"\"\n",
    "    return tx_df \\\n",
    "        .select(\n",
    "            col(\"hash\").alias(\"tx_hash\"),\n",
    "            col(\"block_number\"),\n",
    "            col(\"block_timestamp\"),\n",
    "            col(\"is_coinbase\"),\n",
    "            explode_outer(\"inputs\").alias(\"input\")\n",
    "        ) \\\n",
    "        .select(\n",
    "            \"tx_hash\",\n",
    "            \"block_number\",\n",
    "            \"block_timestamp\",\n",
    "            \"is_coinbase\",\n",
    "            col(\"input.index\").alias(\"input_index\"),\n",
    "            col(\"input.spent_transaction_hash\").alias(\"spent_tx_hash\"),\n",
    "            col(\"input.spent_output_index\").alias(\"spent_output_index\"),\n",
    "            col(\"input.addresses\").alias(\"addresses\"),\n",
    "            col(\"input.value\").alias(\"value\"),\n",
    "        )\n",
    "\n",
    "# Inputs extrahieren\n",
    "inputs_df = explode_inputs(tx_df).cache()\n",
    "INPUT_COUNT = inputs_df.count()\n",
    "print(f\"Inputs extrahiert: {INPUT_COUNT:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. UTXO berechnen: Outputs MINUS Spent = Unspent\n",
    "\n",
    "```\n",
    "┌──────────────────────────────────────────────────────────────────────┐\n",
    "│                       ALLE OUTPUTS                                   │\n",
    "│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐                 │\n",
    "│  │ TX-1:0  │  │ TX-1:1  │  │ TX-2:0  │  │ TX-3:0  │                 │\n",
    "│  │ 5 BTC   │  │ 2 BTC   │  │ 10 BTC  │  │ 1 BTC   │                 │\n",
    "│  └────┬────┘  └─────────┘  └─────────┘  └─────────┘                 │\n",
    "│       │                                                              │\n",
    "│       ▼ wurde ausgegeben                                             │\n",
    "│  ┌─────────┐                                                         │\n",
    "│  │ SPENT   │  (wurde als Input in einer anderen TX verwendet)        │\n",
    "│  └─────────┘                                                         │\n",
    "└──────────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ LEFT ANTI JOIN\n",
    "┌──────────────────────────────────────────────────────────────────────┐\n",
    "│                       UTXOs (Unspent)                                │\n",
    "│  ┌─────────┐  ┌─────────┐  ┌─────────┐                              │\n",
    "│  │ TX-1:1  │  │ TX-2:0  │  │ TX-3:0  │   = 13 BTC                   │\n",
    "│  │ 2 BTC   │  │ 10 BTC  │  │ 1 BTC   │   (noch nicht ausgegeben)    │\n",
    "│  └─────────┘  └─────────┘  └─────────┘                              │\n",
    "└──────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Warum LEFT ANTI JOIN?**\n",
    "- Wir behalten alle Outputs, die NICHT in den Inputs vorkommen\n",
    "- \"Anti\" bedeutet: Behalte nur Zeilen OHNE Match\n",
    "- Das Ergebnis sind alle noch nicht ausgegebenen Outputs (UTXOs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_utxo_set(outputs_df, inputs_df):\n",
    "    \"\"\"\n",
    "    Berechnet das UTXO Set (Unspent Transaction Outputs).\n",
    "    UTXO = Alle Outputs MINUS die, die schon ausgegeben wurden.\n",
    "    \"\"\"\n",
    "    # Alle ausgegebenen Outputs (Referenzen aus Inputs)\n",
    "    spent_refs = inputs_df \\\n",
    "        .filter(col(\"is_coinbase\") == False) \\\n",
    "        .select(\n",
    "            col(\"spent_tx_hash\").alias(\"ref_tx_hash\"),\n",
    "            col(\"spent_output_index\").alias(\"ref_output_index\")\n",
    "        ) \\\n",
    "        .distinct()\n",
    "\n",
    "    # LEFT ANTI JOIN: Behalte nur Outputs die NICHT spent sind\n",
    "    utxos = outputs_df.join(\n",
    "        spent_refs,\n",
    "        on=[\n",
    "            outputs_df.tx_hash == spent_refs.ref_tx_hash,\n",
    "            outputs_df.output_index == spent_refs.ref_output_index\n",
    "        ],\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "    return utxos\n",
    "\n",
    "# UTXO Set berechnen\n",
    "utxo_df = compute_utxo_set(outputs_df, inputs_df).cache()\n",
    "UTXO_COUNT = utxo_df.count()\n",
    "SPENT_COUNT = OUTPUT_COUNT - UTXO_COUNT\n",
    "\n",
    "print(f\"Outputs:  {OUTPUT_COUNT:,}\")\n",
    "print(f\"Spent:    {SPENT_COUNT:,} ({SPENT_COUNT/OUTPUT_COUNT*100:.1f}%)\")\n",
    "print(f\"UTXOs:    {UTXO_COUNT:,} ({UTXO_COUNT/OUTPUT_COUNT*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Common Input Ownership Heuristic\n",
    "\n",
    "Die wichtigste Annahme fuer Address-Clustering:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    MULTI-INPUT TRANSAKTION                          │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   ┌─────────────────┐                                               │\n",
    "│   │  Input 1        │                                               │\n",
    "│   │  Adresse A      │───┐                                           │\n",
    "│   │  (braucht       │   │                                           │\n",
    "│   │   Key A)        │   │      ┌────────────────┐                   │\n",
    "│   └─────────────────┘   │      │                │                   │\n",
    "│                         ├─────▶│  Transaktion   │────▶ Output       │\n",
    "│   ┌─────────────────┐   │      │                │                   │\n",
    "│   │  Input 2        │   │      └────────────────┘                   │\n",
    "│   │  Adresse B      │───┘                                           │\n",
    "│   │  (braucht       │                                               │\n",
    "│   │   Key B)        │                                               │\n",
    "│   └─────────────────┘                                               │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ Schlussfolgerung\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                                                                     │\n",
    "│   Um diese Transaktion zu erstellen, brauchte man BEIDE Keys.       │\n",
    "│                                                                     │\n",
    "│   ┌─────────────────────────────────────────────────────┐           │\n",
    "│   │         Adresse A  +  Adresse B                     │           │\n",
    "│   │              =  SELBER BESITZER                     │           │\n",
    "│   └─────────────────────────────────────────────────────┘           │\n",
    "│                                                                     │\n",
    "│   (mit hoher Wahrscheinlichkeit)                                    │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Wichtig:** Wir nutzen nur INPUTS, nicht Outputs! Bei Outputs wissen wir nicht, wer der Empfaenger ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse: Wie viele Multi-Input Transaktionen gibt es?\n",
    "input_dist = tx_df.filter(col(\"is_coinbase\") == False) \\\n",
    "    .groupBy(\"input_count\").agg(count(\"*\").alias(\"tx_count\")) \\\n",
    "    .orderBy(\"input_count\").toPandas()\n",
    "\n",
    "total_non_coinbase = input_dist['tx_count'].sum()\n",
    "single_input = input_dist[input_dist['input_count'] == 1]['tx_count'].sum()\n",
    "multi_input = input_dist[input_dist['input_count'] > 1]['tx_count'].sum()\n",
    "\n",
    "print(f\"Transaktions-Input Analyse\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Total (ohne Coinbase): {total_non_coinbase:,}\")\n",
    "print(f\"Single-Input:          {single_input:,} ({single_input/total_non_coinbase*100:.1f}%)\")\n",
    "print(f\"Multi-Input:           {multi_input:,} ({multi_input/total_non_coinbase*100:.1f}%) <- nutzbar fuer Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_clustering_inputs(tx_df, outputs_df, min_inputs=2, max_inputs=50):\n",
    "    \"\"\"\n",
    "    Bereitet Inputs aus Multi-Input Transaktionen fuer Clustering vor.\n",
    "    Wir brauchen die Adressen, aber die stehen manchmal nur im Original-Output.\n",
    "    \"\"\"\n",
    "    # Nur Multi-Input Transaktionen (ohne Coinbase)\n",
    "    multi_input_txs = tx_df \\\n",
    "        .filter(\n",
    "            (col(\"input_count\") >= min_inputs) &\n",
    "            (col(\"input_count\") <= max_inputs) &\n",
    "            (col(\"is_coinbase\") == False)\n",
    "        )\n",
    "\n",
    "    # Inputs exploden\n",
    "    inputs_exploded = multi_input_txs \\\n",
    "        .select(\n",
    "            col(\"hash\").alias(\"tx_hash\"),\n",
    "            explode(\"inputs\").alias(\"input\")\n",
    "        ) \\\n",
    "        .select(\n",
    "            \"tx_hash\",\n",
    "            col(\"input.spent_transaction_hash\").alias(\"spent_tx_hash\"),\n",
    "            col(\"input.spent_output_index\").alias(\"spent_output_index\"),\n",
    "            col(\"input.addresses\").alias(\"raw_addresses\"),\n",
    "        )\n",
    "\n",
    "    # Lookup-Tabelle: Original-Output -> Adresse\n",
    "    output_lookup = outputs_df \\\n",
    "        .select(\n",
    "            col(\"tx_hash\").alias(\"source_tx_hash\"),\n",
    "            col(\"output_index\").alias(\"source_output_index\"),\n",
    "            col(\"addresses\").alias(\"source_addresses\"),\n",
    "        )\n",
    "\n",
    "    # Join: Input -> Original Output -> Adresse\n",
    "    enriched = inputs_exploded.join(\n",
    "        output_lookup,\n",
    "        on=[\n",
    "            inputs_exploded.spent_tx_hash == output_lookup.source_tx_hash,\n",
    "            inputs_exploded.spent_output_index == output_lookup.source_output_index\n",
    "        ],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Adresse extrahieren (erste Adresse, falls Array)\n",
    "    enriched = enriched.withColumn(\n",
    "        \"address\",\n",
    "        when(\n",
    "            (col(\"source_addresses\").isNotNull()) & (spark_size(col(\"source_addresses\")) > 0),\n",
    "            element_at(col(\"source_addresses\"), 1)\n",
    "        ).otherwise(\n",
    "            when(\n",
    "                (col(\"raw_addresses\").isNotNull()) & (spark_size(col(\"raw_addresses\")) > 0),\n",
    "                element_at(col(\"raw_addresses\"), 1)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    result = enriched \\\n",
    "        .filter(col(\"address\").isNotNull()) \\\n",
    "        .select(\"tx_hash\", \"address\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Inputs fuer Clustering vorbereiten\n",
    "clustering_inputs = enrich_clustering_inputs(tx_df, outputs_df, min_inputs=2, max_inputs=50).cache()\n",
    "print(f\"Inputs fuer Clustering vorbereitet: {clustering_inputs.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Graph bauen: Adressen als Netzwerk\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    TRANSAKTIONEN                                    │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   TX-1: Inputs von [A, B]       TX-2: Inputs von [B, C]            │\n",
    "│   TX-3: Inputs von [D, E]       TX-4: Inputs von [F]   (nur 1)     │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ Kanten erstellen\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    GRAPH-KANTEN                                     │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   ┌─────────────────────────────────────────────────────────┐      │\n",
    "│   │  src  │  dst  │   Bedeutung                             │      │\n",
    "│   ├───────┼───────┼─────────────────────────────────────────┤      │\n",
    "│   │   A   │   B   │   A und B waren zusammen Input in TX-1  │      │\n",
    "│   │   B   │   C   │   B und C waren zusammen Input in TX-2  │      │\n",
    "│   │   D   │   E   │   D und E waren zusammen Input in TX-3  │      │\n",
    "│   └───────┴───────┴─────────────────────────────────────────┘      │\n",
    "│                                                                     │\n",
    "│   TX-4 erzeugt keine Kante (nur 1 Input)                           │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ Als Graph\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                                                                     │\n",
    "│        A ─────── B ─────── C              D ─────── E               │\n",
    "│                                                                     │\n",
    "│        └─── Entity 1 ───┘                 └ Entity 2┘               │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Transitive Verknuepfung:** A-B (TX-1) + B-C (TX-2) = A-B-C sind EINE Entity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Pro Transaktion: Alle Adressen sammeln\n",
    "tx_addresses = clustering_inputs.groupBy(\"tx_hash\").agg(collect_set(\"address\").alias(\"addresses\"))\n",
    "tx_addresses = tx_addresses.filter(spark_size(\"addresses\") >= 2)\n",
    "\n",
    "# Kanten erstellen: Jedes Paar von Adressen in einer TX\n",
    "def create_edges_udf(addresses):\n",
    "    if not addresses or len(addresses) < 2:\n",
    "        return []\n",
    "    # Alle Paare bilden (Kombinationen)\n",
    "    return [(a, b) for a, b in combinations(sorted(addresses), 2)]\n",
    "\n",
    "edge_schema = ArrayType(StructType([StructField(\"src\", StringType()), StructField(\"dst\", StringType())]))\n",
    "create_edges = udf(create_edges_udf, edge_schema)\n",
    "\n",
    "# Kanten DataFrame\n",
    "edges_df = tx_addresses.withColumn(\"edges\", create_edges(\"addresses\")) \\\n",
    "    .select(explode(\"edges\").alias(\"edge\")) \\\n",
    "    .select(col(\"edge.src\").alias(\"src\"), col(\"edge.dst\").alias(\"dst\")).distinct()\n",
    "\n",
    "# Speichern (fuer Checkpointing)\n",
    "edges_path = str(Path(OUTPUT_PATH) / \"edges_temp.parquet\")\n",
    "edges_df.write.mode(\"overwrite\").parquet(edges_path)\n",
    "edges_df = spark.read.parquet(edges_path).cache()\n",
    "\n",
    "# Knoten (alle Adressen)\n",
    "vertices_df = edges_df.select(col(\"src\").alias(\"id\")).union(edges_df.select(col(\"dst\").alias(\"id\"))).distinct()\n",
    "vertices_path = str(Path(OUTPUT_PATH) / \"vertices_temp.parquet\")\n",
    "vertices_df.write.mode(\"overwrite\").parquet(vertices_path)\n",
    "vertices_df = spark.read.parquet(vertices_path).cache()\n",
    "\n",
    "EDGE_COUNT = edges_df.count()\n",
    "VERTEX_COUNT = vertices_df.count()\n",
    "print(f\"Graph erstellt: {VERTEX_COUNT:,} Knoten (Adressen) | {EDGE_COUNT:,} Kanten (Co-Input Paare)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Connected Components: Entities finden\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    CONNECTED COMPONENTS ALGORITHMUS                 │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   Graph:                                                            │\n",
    "│                                                                     │\n",
    "│       A ─── B ─── C           D ─── E           F                   │\n",
    "│                                                                     │\n",
    "│   A und C sind nicht direkt verbunden, aber transitiv ueber B.      │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ Connected Components\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    ERGEBNIS: ENTITIES                               │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   ┌────────────────┐  ┌────────────────┐  ┌────────────────┐       │\n",
    "│   │   Entity 1     │  │   Entity 2     │  │   Entity 3     │       │\n",
    "│   │   A, B, C      │  │   D, E         │  │   F            │       │\n",
    "│   │                │  │                │  │   (isoliert)   │       │\n",
    "│   └────────────────┘  └────────────────┘  └────────────────┘       │\n",
    "│                                                                     │\n",
    "│   Jede zusammenhaengende Komponente = 1 Entity (Besitzer)          │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**GraphFrames:** Spark-Bibliothek fuer Graph-Algorithmen auf grossen Datenmengen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# GraphFrames importieren und Graph erstellen\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "graph = GraphFrame(vertices_df, edges_df)\n",
    "\n",
    "# Connected Components berechnen\n",
    "# Jede Adresse bekommt eine \"component\" ID - alle Adressen mit gleicher ID gehoeren zusammen\n",
    "entities_df = graph.connectedComponents(algorithm=\"graphframes\", checkpointInterval=1, broadcastThreshold=100000)\n",
    "\n",
    "# Ergebnis speichern\n",
    "entities_path = str(Path(OUTPUT_PATH) / \"entities_temp.parquet\")\n",
    "entities_df.write.mode(\"overwrite\").parquet(entities_path)\n",
    "entities_df = spark.read.parquet(entities_path).cache()\n",
    "\n",
    "ADDRESS_COUNT = entities_df.count()\n",
    "ENTITY_COUNT = entities_df.select(\"component\").distinct().count()\n",
    "REDUCTION = (1 - ENTITY_COUNT/ADDRESS_COUNT) * 100\n",
    "\n",
    "print(f\"\\nClustering Ergebnis\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Adressen analysiert:   {ADDRESS_COUNT:,}\")\n",
    "print(f\"Entities identifiziert: {ENTITY_COUNT:,}\")\n",
    "print(f\"Reduktion:             {REDUCTION:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Whale Detection: Grosse Besitzer finden\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    ENTITY BALANCE BERECHNUNG                        │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   ┌───────────────────┐      ┌───────────────────┐                 │\n",
    "│   │  entities         │      │  utxos            │                 │\n",
    "│   ├───────────────────┤      ├───────────────────┤                 │\n",
    "│   │ Adresse │ Entity  │      │ Adresse │  BTC    │                 │\n",
    "│   │    A    │   1     │      │    A    │  500    │                 │\n",
    "│   │    B    │   1     │      │    B    │  300    │                 │\n",
    "│   │    C    │   1     │      │    C    │  200    │                 │\n",
    "│   │    D    │   2     │      │    D    │   50    │                 │\n",
    "│   └───────────────────┘      └───────────────────┘                 │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ JOIN auf Adresse\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    JOINED                                           │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│   ┌────────────────────────────────────┐                           │\n",
    "│   │ Adresse │ Entity │  BTC            │                           │\n",
    "│   │    A    │   1    │  500            │                           │\n",
    "│   │    B    │   1    │  300            │                           │\n",
    "│   │    C    │   1    │  200            │                           │\n",
    "│   │    D    │   2    │   50            │                           │\n",
    "│   └────────────────────────────────────┘                           │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼ GROUP BY Entity, SUM(BTC)\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    ENTITY BALANCES                                  │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│   ┌───────────────────────────────┐                                │\n",
    "│   │ Entity │  Total BTC           │                                │\n",
    "│   │   1    │  1.000 BTC   <- WAL! │                                │\n",
    "│   │   2    │     50 BTC           │                                │\n",
    "│   └───────────────────────────────┘                                │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Ergebnis:** Entity 1 kontrolliert 1.000 BTC ueber 3 Adressen - das ist ein Wal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Entity-Mapping: Adresse -> Entity ID\n",
    "entities_final = entities_df.select(col(\"id\").alias(\"address\"), col(\"component\").alias(\"entity_id\"))\n",
    "\n",
    "# UTXOs explodieren (eine Zeile pro Adresse)\n",
    "utxo_exploded = utxo_df.select(col(\"tx_hash\"), col(\"output_index\"), col(\"value\"), explode(col(\"addresses\")).alias(\"address\"))\n",
    "\n",
    "# Join: UTXO -> Entity\n",
    "utxo_with_entities = utxo_exploded.join(entities_final, \"address\", \"inner\").select(\"entity_id\", \"value\")\n",
    "\n",
    "# Aggregation: Summe pro Entity\n",
    "entity_balances = utxo_with_entities.groupBy(\"entity_id\").agg(\n",
    "    spark_sum(\"value\").alias(\"balance_satoshi\"),\n",
    "    count(\"*\").alias(\"utxo_count\")\n",
    ").withColumn(\"balance_btc\", spark_round(col(\"balance_satoshi\") / 100000000, 8)).orderBy(desc(\"balance_btc\")).cache()\n",
    "\n",
    "ENTITIES_WITH_BALANCE = entity_balances.count()\n",
    "TOTAL_BTC = entity_balances.agg(spark_sum(\"balance_btc\")).collect()[0][0]\n",
    "\n",
    "print(f\"Entity Balance Zusammenfassung\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Entities mit Guthaben: {ENTITIES_WITH_BALANCE:,}\")\n",
    "print(f\"Total BTC in UTXOs:    {TOTAL_BTC:,.2f} BTC\")\n",
    "print(f\"Durchschnitt/Entity:   {TOTAL_BTC/ENTITIES_WITH_BALANCE:.4f} BTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 Wale\n",
    "top_whales = entity_balances.limit(20).toPandas()\n",
    "TOP_20_BTC = top_whales['balance_btc'].sum()\n",
    "TOP_20_SHARE = TOP_20_BTC / TOTAL_BTC * 100\n",
    "\n",
    "print(f\"Top 20 Wale\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Rang':<6} {'Entity ID':<20} {'Balance (BTC)':<18} {'UTXOs':<10} {'Anteil'}\")\n",
    "print(f\"{'-'*70}\")\n",
    "for i, row in top_whales.iterrows():\n",
    "    share = row['balance_btc'] / TOTAL_BTC * 100\n",
    "    print(f\"#{i+1:<5} {int(row['entity_id']):<20} {row['balance_btc']:>15,.2f}   {int(row['utxo_count']):>8}   {share:>5.2f}%\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"{'Top 20 Total:':<27} {TOP_20_BTC:>15,.2f} BTC         {TOP_20_SHARE:>5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity-Kategorisierung\n",
    "entity_categories = entity_balances.withColumn(\"category\",\n",
    "    when(col(\"balance_btc\") >= 1000, \"Mega Whale (1000+ BTC)\")\n",
    "    .when(col(\"balance_btc\") >= 100, \"Whale (100-1000 BTC)\")\n",
    "    .when(col(\"balance_btc\") >= 10, \"Large (10-100 BTC)\")\n",
    "    .when(col(\"balance_btc\") >= 1, \"Medium (1-10 BTC)\")\n",
    "    .otherwise(\"Small (<1 BTC)\")\n",
    ")\n",
    "\n",
    "category_stats = entity_categories.groupBy(\"category\").agg(\n",
    "    count(\"*\").alias(\"entity_count\"),\n",
    "    spark_sum(\"balance_btc\").alias(\"total_btc\")\n",
    ").orderBy(desc(\"total_btc\")).toPandas()\n",
    "\n",
    "print(\"Kategorie-Verteilung:\")\n",
    "print(category_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualisierung\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    TYPISCHE VERTEILUNG                              │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   BTC-Verteilung:                                                   │\n",
    "│                                                                     │\n",
    "│   ████████████████████████████████████████  Mega Whales (>60%)     │\n",
    "│   ██████████████                            Whales (~25%)          │\n",
    "│   ██████                                    Large (~10%)           │\n",
    "│   ██                                        Medium/Small (~5%)     │\n",
    "│                                                                     │\n",
    "│   Entity-Verteilung:                                                │\n",
    "│                                                                     │\n",
    "│   ██                                        Mega Whales (<1%)      │\n",
    "│   ████                                      Whales (~5%)           │\n",
    "│   ████████████                              Large (~15%)           │\n",
    "│   ████████████████████████████████████████  Medium/Small (>75%)    │\n",
    "│                                                                     │\n",
    "│   = Extreme Konzentration des Reichtums                            │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung: Whale-Analyse\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Top 10 Wale\n",
    "top_10 = entity_balances.limit(10).toPandas()\n",
    "bars = axes[0].barh(range(len(top_10)), top_10['balance_btc'], color=COLORS['primary'])\n",
    "axes[0].set_xlabel('Balance (BTC)')\n",
    "axes[0].set_ylabel('Entity Rang')\n",
    "axes[0].set_title('Top 10 Wale nach Balance')\n",
    "axes[0].set_yticks(range(len(top_10)))\n",
    "axes[0].set_yticklabels([f\"#{i+1}\" for i in range(len(top_10))])\n",
    "axes[0].invert_yaxis()\n",
    "for bar, val in zip(bars, top_10['balance_btc']):\n",
    "    axes[0].text(val + val*0.02, bar.get_y() + bar.get_height()/2, f'{val:,.0f}', va='center', fontsize=9)\n",
    "\n",
    "# Entity-Verteilung nach Kategorie\n",
    "colors_pie = [COLORS['secondary'], COLORS['accent'], COLORS['primary'], '#6B7280', '#D1D5DB']\n",
    "axes[1].pie(category_stats['entity_count'], labels=category_stats['category'], autopct='%1.1f%%',\n",
    "            colors=colors_pie[:len(category_stats)], startangle=90, textprops={'fontsize': 9})\n",
    "axes[1].set_title('Entity-Verteilung nach Kategorie')\n",
    "\n",
    "# BTC-Verteilung nach Kategorie\n",
    "axes[2].pie(category_stats['total_btc'], labels=category_stats['category'], autopct='%1.1f%%',\n",
    "            colors=colors_pie[:len(category_stats)], startangle=90, textprops={'fontsize': 9})\n",
    "axes[2].set_title('BTC-Verteilung nach Kategorie')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(Path(OUTPUT_PATH) / 'whale_analysis.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation: Extreme Reichtumskonzentration - Mega Whales sind <1% der Entities aber halten >60% der BTC.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten speichern\n",
    "entities_final.write.mode(\"overwrite\").parquet(str(Path(OUTPUT_PATH) / \"entities.parquet\"))\n",
    "utxo_df.write.mode(\"overwrite\").parquet(str(Path(OUTPUT_PATH) / \"utxos.parquet\"))\n",
    "outputs_df.write.mode(\"overwrite\").parquet(str(Path(OUTPUT_PATH) / \"outputs.parquet\"))\n",
    "inputs_df.write.mode(\"overwrite\").parquet(str(Path(OUTPUT_PATH) / \"inputs.parquet\"))\n",
    "\n",
    "print(f\"Daten exportiert nach {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenfassende Metriken berechnen\n",
    "mega_whales = category_stats[category_stats['category'] == 'Mega Whale (1000+ BTC)']\n",
    "MEGA_WHALE_COUNT = int(mega_whales['entity_count'].values[0]) if len(mega_whales) > 0 else 0\n",
    "MEGA_WHALE_BTC = float(mega_whales['total_btc'].values[0]) if len(mega_whales) > 0 else 0\n",
    "MEGA_WHALE_SHARE = MEGA_WHALE_BTC / TOTAL_BTC * 100 if TOTAL_BTC > 0 else 0\n",
    "\n",
    "print(f\"\"\"\n",
    "{'='*70}\n",
    "                    BITCOIN WHALE INTELLIGENCE REPORT\n",
    "{'='*70}\n",
    "\n",
    "DATENUMFANG\n",
    "{'-'*70}\n",
    "  Bloecke analysiert:      {BLOCK_COUNT:>15,}\n",
    "  Transaktionen:           {TX_COUNT:>15,}\n",
    "  Outputs erstellt:        {OUTPUT_COUNT:>15,}\n",
    "  UTXOs (unspent):         {UTXO_COUNT:>15,}\n",
    "\n",
    "CLUSTERING ERGEBNISSE\n",
    "{'-'*70}\n",
    "  Adressen geclustert:     {ADDRESS_COUNT:>15,}\n",
    "  Entities identifiziert:  {ENTITY_COUNT:>15,}\n",
    "  Clustering-Reduktion:    {REDUCTION:>14.1f}%\n",
    "\n",
    "WHALE-ANALYSE\n",
    "{'-'*70}\n",
    "  Total BTC erfasst:       {TOTAL_BTC:>15,.2f} BTC\n",
    "  Mega Whales (1000+ BTC): {MEGA_WHALE_COUNT:>15,}\n",
    "  Mega Whale Holdings:     {MEGA_WHALE_BTC:>15,.2f} BTC ({MEGA_WHALE_SHARE:.1f}%)\n",
    "  Top 20 Konzentration:    {TOP_20_BTC:>15,.2f} BTC ({TOP_20_SHARE:.1f}%)\n",
    "\n",
    "WICHTIGE ERKENNTNISSE\n",
    "{'-'*70}\n",
    "  1. Hohe Konzentration: Top 20 Entities kontrollieren {TOP_20_SHARE:.1f}% der BTC\n",
    "  2. Power-Law Verteilung: Wenige grosse Wale, viele kleine Entities\n",
    "  3. Clustering effektiv: {REDUCTION:.1f}% Adress-Reduktion erreicht\n",
    "\n",
    "WAHRSCHEINLICHE WAL-IDENTITAETEN\n",
    "{'-'*70}\n",
    "  - Mega Whales (1000+ BTC): Early Adopter, Boersen, Institutionen\n",
    "  - Whales (100-1000 BTC): Mining Pools, grosse Trader, Services\n",
    "  - Large (10-100 BTC): Aktive Trader, Unternehmen, wohlhabende Privatpersonen\n",
    "\n",
    "{'='*70}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abschluss-Visualisierung: Key Metrics Overview\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "metrics = [\n",
    "    f'Transaktionen\\n{TX_COUNT:,}',\n",
    "    f'Adressen\\n{ADDRESS_COUNT:,}',\n",
    "    f'Entities\\n{ENTITY_COUNT:,}',\n",
    "    f'Total BTC\\n{TOTAL_BTC:,.0f}',\n",
    "    f'Mega Whales\\n{MEGA_WHALE_COUNT}'\n",
    "]\n",
    "values = [TX_COUNT, ADDRESS_COUNT, ENTITY_COUNT, TOTAL_BTC, MEGA_WHALE_COUNT]\n",
    "normalized = [v / max(values) for v in values]\n",
    "\n",
    "bars = ax.bar(metrics, normalized, color=[COLORS['primary'], COLORS['secondary'], COLORS['accent'], COLORS['dark'], COLORS['secondary']])\n",
    "ax.set_ylabel('Relative Skala', fontsize=12)\n",
    "ax.set_title('Bitcoin Whale Intelligence: Wichtige Metriken', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_ylim(0, 1.15)\n",
    "\n",
    "for bar, val, norm in zip(bars, values, normalized):\n",
    "    if val >= 1000:\n",
    "        label = f'{val:,.0f}'\n",
    "    else:\n",
    "        label = str(int(val))\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, norm + 0.03, label, ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.text(0.5, -0.15, f'Top 20 Whale Konzentration: {TOP_20_SHARE:.1f}% aller BTC | Clustering Reduktion: {REDUCTION:.1f}%',\n",
    "        transform=ax.transAxes, ha='center', fontsize=12, style='italic', color=COLORS['dark'])\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(Path(OUTPUT_PATH) / 'executive_summary.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session (optional beenden)\n",
    "# spark.stop()\n",
    "print(\"Analyse abgeschlossen. Spark Session bleibt aktiv fuer weitere Erkundung.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Zusammenfassung: Die komplette Pipeline\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    BITCOIN WHALE INTELLIGENCE PIPELINE                      │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│   ┌─────────┐                                                               │\n",
    "│   │  JSON   │  Blockchain-Daten von bitcoin-etl                            │\n",
    "│   └────┬────┘                                                               │\n",
    "│        │                                                                    │\n",
    "│        ▼                                                                    │\n",
    "│   ┌─────────────────────────────────────────────────────┐                  │\n",
    "│   │ Schritt 1+2: Outputs & Inputs extrahieren (explode) │                  │\n",
    "│   └────────────────────────┬────────────────────────────┘                  │\n",
    "│                            │                                                │\n",
    "│        ┌───────────────────┼───────────────────┐                           │\n",
    "│        ▼                   ▼                   ▼                           │\n",
    "│   ┌─────────┐         ┌─────────┐         ┌─────────┐                      │\n",
    "│   │ outputs │         │ inputs  │         │ inputs  │                      │\n",
    "│   └────┬────┘         └────┬────┘         └────┬────┘                      │\n",
    "│        │                   │                   │                           │\n",
    "│        └─────────┬─────────┘                   │                           │\n",
    "│                  ▼                             │                           │\n",
    "│   ┌──────────────────────────┐                 │                           │\n",
    "│   │ Schritt 3: UTXO berechnen│                 │                           │\n",
    "│   │   (LEFT ANTI JOIN)       │                 │                           │\n",
    "│   └────────────┬─────────────┘                 │                           │\n",
    "│                │                               │                           │\n",
    "│                ▼                               ▼                           │\n",
    "│   ┌─────────┐              ┌───────────────────────────────┐               │\n",
    "│   │  utxos  │              │ Schritt 4a: Multi-Input Kanten│               │\n",
    "│   └────┬────┘              │        (Adress-Paare)         │               │\n",
    "│        │                   └───────────────┬───────────────┘               │\n",
    "│        │                                   │                               │\n",
    "│        │                                   ▼                               │\n",
    "│        │                   ┌───────────────────────────────┐               │\n",
    "│        │                   │ Schritt 4b: Connected         │               │\n",
    "│        │                   │   Components (GraphFrames)    │               │\n",
    "│        │                   └───────────────┬───────────────┘               │\n",
    "│        │                                   │                               │\n",
    "│        │                                   ▼                               │\n",
    "│        │                              ┌─────────┐                          │\n",
    "│        │                              │entities │                          │\n",
    "│        │                              └────┬────┘                          │\n",
    "│        │                                   │                               │\n",
    "│        └─────────────────┬─────────────────┘                               │\n",
    "│                          ▼                                                 │\n",
    "│           ┌──────────────────────────────┐                                 │\n",
    "│           │ Schritt 5: Whale Detection   │                                 │\n",
    "│           │   (JOIN + GROUP BY + SUM)    │                                 │\n",
    "│           └──────────────┬───────────────┘                                 │\n",
    "│                          │                                                 │\n",
    "│                          ▼                                                 │\n",
    "│                     ┌─────────┐                                            │\n",
    "│                     │  WALE   │  Entity-Balancen > Schwellenwert           │\n",
    "│                     └─────────┘                                            │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
